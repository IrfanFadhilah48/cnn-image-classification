{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrfanFadhilah48/cnn-image-classification/blob/master/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvnoCqXrty5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "909141f1-0295-4b08-999f-52bed03380f1"
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'2698_Kelompok6(3IA14).lyx~.gdoc'\n",
            "'3. Pemilihan Database.gdoc'\n",
            " apk\n",
            " Aplikasi.apk\n",
            " app-debug.apk\n",
            " AppPencarianProperti.zip\n",
            "'BAB IIIcompressed.pdf'\n",
            "'build (1).prop.gdoc'\n",
            " build.prop.gdoc\n",
            " Capture1.PNG\n",
            " Classroom\n",
            " coba3.html\n",
            "'Colab Notebooks'\n",
            " Dataset\n",
            " doc.pdf\n",
            "'Evaluasi Aplikasi MyCat.gform'\n",
            " FlashLight.zip\n",
            " FootballMatchScheduleTest.zip\n",
            "'Formulir tanpa judul (1).gform'\n",
            "'Formulir tanpa judul.gform'\n",
            "'health (1).gdoc'\n",
            " health.gdoc\n",
            "'IAK intermediate'\n",
            "'iak inter.PNG'\n",
            "'KELOMPOK 5.pptx'\n",
            "'MovieApp (1).apk'\n",
            " MovieApp.apk\n",
            " MyCat.apk\n",
            "'Nur Irfan Eka Fadhilah_55415187_Grafik Komputer 2.zip'\n",
            "'Nur Irfan Eka Fadhilah_55415187 - Nurirfan eka fadhilah.pdf'\n",
            "'Nur Irfan Eka Fadhilah_55415187.pdf'\n",
            " Pong2D.zip\n",
            "'proposal kelompok 4 (1).gdoc'\n",
            "'proposal kelompok 4.gdoc'\n",
            "'proposal kelompok 4.pdf'\n",
            "'SAP Arsitektur Komputer_AK-045203 (1).htm.gdoc'\n",
            "'SAP Arsitektur Komputer_AK-045203 (2).htm.gdoc'\n",
            "'SAP Arsitektur Komputer_AK-045203.htm.gdoc'\n",
            " SBD\n",
            " Screenshot_20180731-205438.jpg\n",
            " Screenshot_20180917-193129.jpg\n",
            " skripsweet\n",
            " Skripsweet\n",
            " tampilanawal2.html\n",
            " tampilanawal.html\n",
            "'Tugas GRAFKOM'\n",
            "'uevent (1).gdoc'\n",
            "'uevent (2).gdoc'\n",
            "'uevent (3).gdoc'\n",
            "'uevent (4).gdoc'\n",
            "'uevent (5).gdoc'\n",
            "'uevent (6).gdoc'\n",
            " uevent.gdoc\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " voltage_max.gdoc\n",
            " voltage_now.gdoc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocyShlyQle5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd6164a1-0e2e-477d-9358-8956448d47fb"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "# Installing Theano\n",
        "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
        "\n",
        "# Installing Tensorflow\n",
        "# pip install tensorflow\n",
        "\n",
        "# Installing Keras\n",
        "# pip install --upgrade keras\n",
        "\n",
        "# Part 1 - Building the CNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# tambahan\n",
        "\n",
        "# Step 1 - Convolution\n",
        "# Convolution - input image, applying feature detectors => feature map\n",
        "# 3D Array because colored images\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "# Feature Map - Take Max -> Pooled Feature Map, reduced size, reduce complexity\n",
        "# without losing performance, don't lose spatial structure\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding second convolution layer\n",
        "# don't need to include input_shape since we're done it\n",
        "# classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# tambahan\n",
        "# classifier.add(Conv2D(16, (3, 3), activation = 'relu'))\n",
        "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "# Pooled Feature Maps apply flattening maps to a huge vector \n",
        "# for a future ANN that is fully-conntected\n",
        "# Why don't we lose spatial structure by flattening?\n",
        "# We don't because the high numbers from convolution feature from the feature detector\n",
        "# Max Pooling keeps them these high numbers, and flattening keeps these high numbers\n",
        "# Why didn't we take all the pixels and flatten into a huge vector?\n",
        "# Only pixels of itself, but not how they're spatially structured around it\n",
        "# But if we apply convolution and pooling, since feature map corresponds to each feature \n",
        "# of an image, specific image unique pixels, we keep the spatial structure of the picture.\n",
        "classifier.add(Flatten())\n",
        "\n",
        "\n",
        "# Step 4 - Full Connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "# classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile - SGD, Loss Function, Performance Metric\n",
        "# Logarithmic loss - binary cross entropy, more than two outcomes, categorical cross entropy\n",
        "# Metrics is the accuracy metric\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# part 2 - Fitting the CNN to the images \n",
        "# Keras preprocessing images to prevent overfitting, image augmentation, \n",
        "# great accuracy on training poor results on test sets\n",
        "# Need lots of images to find correlations, patterns in pixels\n",
        "# Find patterns in pixels, 10000 images, 8000 training, not much exactly or use a trick\n",
        "# Image augmentation will create batches and each batch will create random transformation\n",
        "# leading to more diverse images and more training\n",
        "# Image augmentation allows us to enrich our dataset to prevent overfitting\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Dataset/Transportation/training_set/',\n",
        "                                                 target_size=(64, 64),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical')\n",
        "                                                #  class_mode='binary')\n",
        "\n",
        "# test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Dataset/Transportation/test_set',\n",
        "                                            target_size=(64, 64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical')\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "                        # samples_per_epoch=8000,\n",
        "                        samples_per_epoch=2000,\n",
        "                        nb_epoch=200,\n",
        "                        # nb_epoch=1,\n",
        "                        validation_data=test_set,\n",
        "                        nb_val_samples=1000)\n",
        "                        # nb_val_samples=2000)\n",
        "\n",
        "# classifier.save_weights('bottleneck_3_epochs.h5')\n",
        "classifier.save('flags.model')\n",
        "# Part 3 - Making new predictions\n",
        "# test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size=(64, 64))\n",
        "# test_image = image.img_to_array(test_image)\n",
        "# test_image = np.expand_dims(test_image, axis = 0)\n",
        "# result = classifier.predict(test_image)\n",
        "# training_set.class_indices\n",
        "# if result[0][0] == 1: \n",
        "#     prediction = 'dog'\n",
        "#     print('dog')\n",
        "#     print(result)\n",
        "# else:\n",
        "#     prediction = 'cat'\n",
        "#     print('cat')\n",
        "#     print(result)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2483 images belonging to 3 classes.\n",
            "Found 1593 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=62, epochs=200, validation_steps=1000)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 459s 7s/step - loss: 0.3540 - acc: 0.8317 - val_loss: 0.1588 - val_acc: 0.9427\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 126s 2s/step - loss: 0.1220 - acc: 0.9553 - val_loss: 0.0616 - val_acc: 0.9787\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 124s 2s/step - loss: 0.0959 - acc: 0.9632 - val_loss: 0.1329 - val_acc: 0.9508\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 124s 2s/step - loss: 0.0733 - acc: 0.9696 - val_loss: 0.0818 - val_acc: 0.9686\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0715 - acc: 0.9740 - val_loss: 0.0326 - val_acc: 0.9897\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0379 - acc: 0.9855 - val_loss: 0.0253 - val_acc: 0.9906\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0547 - acc: 0.9798 - val_loss: 0.0692 - val_acc: 0.9734\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0480 - acc: 0.9830 - val_loss: 0.0145 - val_acc: 0.9939\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 122s 2s/step - loss: 0.0324 - acc: 0.9894 - val_loss: 0.0253 - val_acc: 0.9902\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0304 - acc: 0.9894 - val_loss: 0.0258 - val_acc: 0.9904\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0291 - acc: 0.9893 - val_loss: 0.0164 - val_acc: 0.9931\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0296 - acc: 0.9894 - val_loss: 0.0383 - val_acc: 0.9847\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0351 - acc: 0.9883 - val_loss: 0.0310 - val_acc: 0.9887\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 123s 2s/step - loss: 0.0148 - acc: 0.9951 - val_loss: 0.0119 - val_acc: 0.9960\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.0114 - val_acc: 0.9960\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 121s 2s/step - loss: 0.0118 - acc: 0.9960 - val_loss: 0.0028 - val_acc: 0.9992\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 123s 2s/step - loss: 0.0125 - acc: 0.9951 - val_loss: 0.0167 - val_acc: 0.9946\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 122s 2s/step - loss: 0.0279 - acc: 0.9896 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 121s 2s/step - loss: 0.0108 - acc: 0.9982 - val_loss: 0.0089 - val_acc: 0.9969\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 124s 2s/step - loss: 0.0177 - acc: 0.9931 - val_loss: 0.0045 - val_acc: 0.9987\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 115s 2s/step - loss: 0.0140 - acc: 0.9966 - val_loss: 0.0092 - val_acc: 0.9979\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0169 - acc: 0.9931 - val_loss: 0.0033 - val_acc: 0.9983\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 125s 2s/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0041 - val_acc: 0.9987\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0097 - val_acc: 0.9971\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0210 - acc: 0.9940 - val_loss: 0.0098 - val_acc: 0.9954\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 0.0213 - acc: 0.9914 - val_loss: 0.0029 - val_acc: 0.9996\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 0.0109 - acc: 0.9953 - val_loss: 0.0014 - val_acc: 0.9992\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0162 - acc: 0.9943 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0021 - val_acc: 0.9992\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0120 - acc: 0.9946 - val_loss: 0.0058 - val_acc: 0.9975\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.0050 - val_acc: 0.9987\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0073 - acc: 0.9968 - val_loss: 0.0029 - val_acc: 0.9992\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0183 - acc: 0.9950 - val_loss: 0.0065 - val_acc: 0.9973\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0155 - acc: 0.9945 - val_loss: 0.0088 - val_acc: 0.9969\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0138 - acc: 0.9936 - val_loss: 0.0089 - val_acc: 0.9975\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0190 - acc: 0.9933 - val_loss: 0.0413 - val_acc: 0.9851\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0148 - acc: 0.9938 - val_loss: 0.0055 - val_acc: 0.9975\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0034 - val_acc: 0.9979\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0123 - acc: 0.9951 - val_loss: 0.0101 - val_acc: 0.9967\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0046 - acc: 0.9973 - val_loss: 0.0046 - val_acc: 0.9979\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0097 - acc: 0.9966 - val_loss: 3.0319e-04 - val_acc: 1.0000\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0041 - acc: 0.9990 - val_loss: 7.0630e-04 - val_acc: 0.9996\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.0086 - val_acc: 0.9967\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0099 - acc: 0.9960 - val_loss: 6.6840e-04 - val_acc: 1.0000\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0097 - acc: 0.9980 - val_loss: 4.5987e-04 - val_acc: 1.0000\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 109s 2s/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0042 - acc: 0.9993 - val_loss: 8.0322e-04 - val_acc: 1.0000\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0272 - acc: 0.9909 - val_loss: 8.3315e-04 - val_acc: 1.0000\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0016 - val_acc: 0.9992\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 110s 2s/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.0023 - val_acc: 0.9992\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 109s 2s/step - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0070 - val_acc: 0.9967\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 109s 2s/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0014 - val_acc: 0.9996\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 106s 2s/step - loss: 0.0080 - acc: 0.9967 - val_loss: 0.0037 - val_acc: 0.9983\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 106s 2s/step - loss: 0.0083 - acc: 0.9970 - val_loss: 0.0075 - val_acc: 0.9975\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 105s 2s/step - loss: 0.0048 - acc: 0.9983 - val_loss: 6.7562e-04 - val_acc: 1.0000\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 104s 2s/step - loss: 0.0165 - acc: 0.9951 - val_loss: 0.0027 - val_acc: 0.9992\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 104s 2s/step - loss: 0.0051 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9983\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 103s 2s/step - loss: 0.0089 - acc: 0.9965 - val_loss: 0.0038 - val_acc: 0.9983\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 107s 2s/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 108s 2s/step - loss: 0.0084 - acc: 0.9968 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 109s 2s/step - loss: 0.0017 - acc: 0.9993 - val_loss: 9.1252e-04 - val_acc: 1.0000\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0025 - acc: 0.9987 - val_loss: 0.0121 - val_acc: 0.9960\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 115s 2s/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0064 - val_acc: 0.9979\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 117s 2s/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0036 - val_acc: 0.9983\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0197 - acc: 0.9931 - val_loss: 0.0037 - val_acc: 0.9987\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 123s 2s/step - loss: 0.0091 - acc: 0.9963 - val_loss: 0.0064 - val_acc: 0.9969\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 122s 2s/step - loss: 0.0041 - acc: 0.9990 - val_loss: 2.5431e-04 - val_acc: 1.0000\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 0.0028 - acc: 0.9990 - val_loss: 5.0845e-05 - val_acc: 1.0000\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 0.9992\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0085 - val_acc: 0.9979\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 8.2930e-04 - acc: 1.0000 - val_loss: 3.7143e-04 - val_acc: 1.0000\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0036 - acc: 0.9980 - val_loss: 0.0046 - val_acc: 0.9987\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0127 - acc: 0.9967 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0252 - acc: 0.9933 - val_loss: 7.3913e-04 - val_acc: 0.9996\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 126s 2s/step - loss: 0.0032 - acc: 0.9993 - val_loss: 1.9716e-04 - val_acc: 1.0000\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 125s 2s/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0012 - val_acc: 0.9996\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 122s 2s/step - loss: 0.0082 - acc: 0.9975 - val_loss: 1.2010e-04 - val_acc: 1.0000\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0049 - acc: 0.9976 - val_loss: 6.7885e-04 - val_acc: 1.0000\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0048 - acc: 0.9987 - val_loss: 7.2693e-04 - val_acc: 0.9996\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0016 - acc: 0.9992 - val_loss: 1.1874e-04 - val_acc: 1.0000\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0021 - val_acc: 0.9992\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.7795e-04 - val_acc: 0.9996\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0017 - acc: 0.9990 - val_loss: 5.4659e-04 - val_acc: 0.9996\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 2.2655e-04 - acc: 1.0000 - val_loss: 3.4958e-04 - val_acc: 1.0000\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 0.0060 - acc: 0.9976 - val_loss: 0.0087 - val_acc: 0.9977\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 117s 2s/step - loss: 0.0024 - acc: 0.9990 - val_loss: 5.1515e-05 - val_acc: 1.0000\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 121s 2s/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0024 - val_acc: 0.9996\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0011 - val_acc: 0.9992\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0051 - val_acc: 0.9983\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 115s 2s/step - loss: 0.0049 - acc: 0.9976 - val_loss: 0.0042 - val_acc: 0.9996\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0046 - val_acc: 0.9977\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0161 - acc: 0.9945 - val_loss: 3.8774e-04 - val_acc: 1.0000\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 112s 2s/step - loss: 0.0065 - acc: 0.9976 - val_loss: 0.0014 - val_acc: 0.9996\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 115s 2s/step - loss: 0.0157 - acc: 0.9939 - val_loss: 0.0029 - val_acc: 0.9987\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0117 - val_acc: 0.9962\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0040 - acc: 0.9983 - val_loss: 2.6565e-04 - val_acc: 1.0000\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 115s 2s/step - loss: 6.1592e-04 - acc: 0.9998 - val_loss: 9.7369e-05 - val_acc: 1.0000\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0013 - acc: 0.9993 - val_loss: 1.6323e-04 - val_acc: 1.0000\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 5.1605e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9992\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0024 - val_acc: 0.9996\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 0.0050 - acc: 0.9987 - val_loss: 6.8119e-04 - val_acc: 1.0000\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 111s 2s/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0024 - val_acc: 0.9987\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 109s 2s/step - loss: 0.0081 - acc: 0.9966 - val_loss: 0.0032 - val_acc: 0.9987\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 109s 2s/step - loss: 0.0068 - acc: 0.9976 - val_loss: 0.0027 - val_acc: 0.9992\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 0.0103 - acc: 0.9963 - val_loss: 0.0041 - val_acc: 0.9979\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 0.0041 - acc: 0.9983 - val_loss: 3.1265e-05 - val_acc: 1.0000\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 0.0052 - acc: 0.9976 - val_loss: 1.0980e-04 - val_acc: 1.0000\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0015 - acc: 0.9993 - val_loss: 5.1561e-04 - val_acc: 0.9996\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 2.6265e-04 - acc: 1.0000 - val_loss: 5.9692e-05 - val_acc: 1.0000\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 123s 2s/step - loss: 0.0026 - acc: 0.9990 - val_loss: 1.3469e-04 - val_acc: 1.0000\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 2.8236e-04 - acc: 1.0000 - val_loss: 2.2521e-05 - val_acc: 1.0000\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 114s 2s/step - loss: 2.2772e-04 - acc: 1.0000 - val_loss: 2.1310e-05 - val_acc: 1.0000\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 113s 2s/step - loss: 8.2640e-04 - acc: 0.9997 - val_loss: 0.0033 - val_acc: 0.9992\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 117s 2s/step - loss: 0.0032 - acc: 0.9990 - val_loss: 1.3433e-04 - val_acc: 1.0000\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 115s 2s/step - loss: 0.0044 - acc: 0.9980 - val_loss: 1.7679e-04 - val_acc: 1.0000\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 117s 2s/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0041 - val_acc: 0.9992\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 120s 2s/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.0011 - val_acc: 0.9992\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0064 - acc: 0.9976 - val_loss: 0.0021 - val_acc: 0.9992\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 119s 2s/step - loss: 0.0095 - acc: 0.9970 - val_loss: 3.6976e-04 - val_acc: 1.0000\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 127s 2s/step - loss: 0.0062 - acc: 0.9973 - val_loss: 8.7721e-05 - val_acc: 1.0000\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 126s 2s/step - loss: 0.0013 - acc: 0.9997 - val_loss: 1.0842e-04 - val_acc: 1.0000\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 127s 2s/step - loss: 2.2646e-04 - acc: 1.0000 - val_loss: 6.4511e-06 - val_acc: 1.0000\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 2.3424e-04 - acc: 1.0000 - val_loss: 3.1210e-05 - val_acc: 1.0000\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 0.0031 - acc: 0.9993 - val_loss: 5.4357e-05 - val_acc: 1.0000\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 116s 2s/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.0200 - val_acc: 0.9927\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 117s 2s/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9996\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 118s 2s/step - loss: 0.0102 - acc: 0.9970 - val_loss: 6.6429e-04 - val_acc: 0.9996\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 121s 2s/step - loss: 0.0030 - acc: 0.9990 - val_loss: 8.9084e-04 - val_acc: 0.9996\n",
            "Epoch 131/200\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9990"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}